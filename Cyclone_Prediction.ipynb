{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785443c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Core Python libraries\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Deep Learning (TensorFlow/Keras)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Image processing\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "# API and web requests\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "# Environment configuration\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de2ecc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 200 rows, 7 columns\n",
      "Cyclone rate: 50.0%\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('cyclone_databased_on_weather.csv')\n",
    "    print(f\"Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    \n",
    "    # Handle missing values\n",
    "    if df.isnull().sum().sum() > 0:\n",
    "        df = df.fillna(df.mean(numeric_only=True))\n",
    "    \n",
    "    # Display cyclone distribution if available\n",
    "    if 'cyclone_occurrence' in df.columns:\n",
    "        cyclone_counts = df['cyclone_occurrence'].value_counts()\n",
    "        cyclone_rate = (cyclone_counts[1] / cyclone_counts.sum() * 100)\n",
    "        print(f\"Cyclone rate: {cyclone_rate:.1f}%\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Creating sample dataset...\")\n",
    "    \n",
    "    # Create sample weather dataset\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Cyclone Name': [f'Cyclone_{i}' if i % 5 == 0 else 'No_Cyclone' for i in range(n_samples)],\n",
    "        'Date': pd.date_range(start='2020-01-01', periods=n_samples, freq='D'),\n",
    "        'Location': np.random.choice(['Bay of Bengal', 'Arabian Sea', 'Pacific Ocean', 'Atlantic Ocean'], n_samples),\n",
    "        'wind_speed': np.abs(np.random.normal(15, 10, n_samples)),\n",
    "        'pressure': np.abs(np.random.normal(1013, 25, n_samples)),\n",
    "        'ocean_temperature': np.abs(np.random.normal(28, 5, n_samples)),\n",
    "        'cyclone_occurrence': np.random.choice([0, 1], n_samples, p=[0.8, 0.2])\n",
    "    })\n",
    "    \n",
    "    df.to_csv('cyclone_databased_on_weather.csv', index=False)\n",
    "    print(f\"Sample dataset created: {df.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62cb4fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split complete: 3 features\n",
      "Training samples: 160\n",
      "Testing samples: 40\n"
     ]
    }
   ],
   "source": [
    "# Select numeric columns for features\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "if 'cyclone_occurrence' in df.columns:\n",
    "    # Features: weather parameters only (exclude target)\n",
    "    feature_columns = [col for col in numeric_columns if col != 'cyclone_occurrence']\n",
    "    X = df[feature_columns].copy()\n",
    "    y = df['cyclone_occurrence'].copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    if X.isnull().any().any():\n",
    "        X = X.fillna(X.mean())\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    print(f\"Data split complete: {X_train_scaled.shape[1]} features\")\n",
    "    print(f\"Training samples: {X_train_scaled.shape[0]}\")\n",
    "    print(f\"Testing samples: {X_test_scaled.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed4f93a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Model Performance:\n",
      "  Accuracy: 1.000\n",
      "  Precision: 1.000\n",
      "  Recall: 1.000\n",
      "  F1-Score: 1.000\n",
      "  ROC AUC: 1.000\n",
      "Weather model saved\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest Classifier\n",
    "weather_model = RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=10, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "weather_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = weather_model.predict(X_test_scaled)\n",
    "y_pred_proba_test = weather_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "precision = precision_score(y_test, y_pred_test)\n",
    "recall = recall_score(y_test, y_pred_test)\n",
    "f1 = f1_score(y_test, y_pred_test)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba_test)\n",
    "\n",
    "print(f\"Weather Model Performance:\")\n",
    "print(f\"  Accuracy: {test_accuracy:.3f}\")\n",
    "print(f\"  Precision: {precision:.3f}\")\n",
    "print(f\"  Recall: {recall:.3f}\")\n",
    "print(f\"  F1-Score: {f1:.3f}\")\n",
    "print(f\"  ROC AUC: {roc_auc:.3f}\")\n",
    "\n",
    "# Save model\n",
    "os.makedirs('models', exist_ok=True)\n",
    "with open('models/weather_model.pkl', 'wb') as f:\n",
    "    pickle.dump(weather_model, f)\n",
    "with open('models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Weather model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "190b9d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satellite dataset: 151 cyclone, 573 non-cyclone images\n",
      "Found 580 images belonging to 2 classes.\n",
      "Found 144 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.7242 - loss: 0.7161"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 471ms/step - accuracy: 0.7265 - loss: 0.7123 - val_accuracy: 0.7917 - val_loss: 0.5192\n",
      "Epoch 2/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 430ms/step - accuracy: 0.7996 - loss: 0.5115 - val_accuracy: 0.7917 - val_loss: 0.5132\n",
      "Epoch 3/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - accuracy: 0.7629 - loss: 0.5386 - val_accuracy: 0.7917 - val_loss: 0.4812\n",
      "Epoch 4/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 389ms/step - accuracy: 0.7838 - loss: 0.5100 - val_accuracy: 0.7917 - val_loss: 0.4778\n",
      "Epoch 5/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.7816 - loss: 0.4983 - val_accuracy: 0.7917 - val_loss: 0.5193\n",
      "Epoch 6/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 380ms/step - accuracy: 0.8186 - loss: 0.4882 - val_accuracy: 0.7917 - val_loss: 0.4830\n",
      "Satellite model training completed\n"
     ]
    }
   ],
   "source": [
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "dataset_path = \"Cyclone_Dataset\"\n",
    "cyclone_dir = os.path.join(dataset_path, 'cyclone')\n",
    "noncyclone_dir = os.path.join(dataset_path, 'noncyclone')\n",
    "\n",
    "if os.path.exists(cyclone_dir) and os.path.exists(noncyclone_dir):\n",
    "    cyclone_count = len([f for f in os.listdir(cyclone_dir) \n",
    "                        if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    noncyclone_count = len([f for f in os.listdir(noncyclone_dir) \n",
    "                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    \n",
    "    if cyclone_count > 0 and noncyclone_count > 0:\n",
    "        print(f\"Satellite dataset: {cyclone_count} cyclone, {noncyclone_count} non-cyclone images\")\n",
    "        \n",
    "        # Create data generators\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255, validation_split=0.2,\n",
    "            rotation_range=20, width_shift_range=0.2,\n",
    "            height_shift_range=0.2, horizontal_flip=True, zoom_range=0.2\n",
    "        )\n",
    "        \n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            dataset_path, target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "            batch_size=BATCH_SIZE, class_mode='binary',\n",
    "            subset='training', seed=42\n",
    "        )\n",
    "        \n",
    "        validation_generator = train_datagen.flow_from_directory(\n",
    "            dataset_path, target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "            batch_size=BATCH_SIZE, class_mode='binary',\n",
    "            subset='validation', seed=42\n",
    "        )\n",
    "        \n",
    "        # Create CNN model\n",
    "        satellite_model = Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "            MaxPooling2D(2, 2),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D(2, 2),\n",
    "            Conv2D(128, (3, 3), activation='relu'),\n",
    "            MaxPooling2D(2, 2),\n",
    "            Conv2D(128, (3, 3), activation='relu'),\n",
    "            MaxPooling2D(2, 2),\n",
    "            Flatten(),\n",
    "            Dropout(0.5),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        satellite_model.compile(\n",
    "            optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True),\n",
    "            ModelCheckpoint('models/satellite_model_best.h5', monitor='val_accuracy', save_best_only=True)\n",
    "        ]\n",
    "        \n",
    "        history = satellite_model.fit(\n",
    "            train_generator, epochs=EPOCHS,\n",
    "            validation_data=validation_generator,\n",
    "            callbacks=callbacks, verbose=1\n",
    "        )\n",
    "        satellite_model.save('models/my_model.keras')\n",
    "        satellite_training_history = history\n",
    "        print(\"Satellite model training completed\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Insufficient images in dataset\")\n",
    "        satellite_model = None\n",
    "        satellite_training_history = None\n",
    "else:\n",
    "    print(\"Cyclone_Dataset directory not found\")\n",
    "    satellite_model = None\n",
    "    satellite_training_history = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30d8d1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satellite Model Performance:\n",
      "  Validation Accuracy: 0.7917\n",
      "  Validation Loss: 0.5201\n",
      "  Sample batch accuracy: 0.844\n"
     ]
    }
   ],
   "source": [
    "if satellite_model is not None and satellite_training_history is not None:\n",
    "    val_loss, val_accuracy = satellite_model.evaluate(validation_generator, verbose=0)\n",
    "    print(f\"Satellite Model Performance:\")\n",
    "    print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Test predictions on sample batch\n",
    "    val_batch = next(validation_generator)\n",
    "    val_images, val_labels = val_batch\n",
    "    predictions = satellite_model.predict(val_images, verbose=0)\n",
    "    predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
    "    batch_accuracy = accuracy_score(val_labels, predicted_classes)\n",
    "    print(f\"  Sample batch accuracy: {batch_accuracy:.3f}\")\n",
    "else:\n",
    "    print(\"Satellite model not available for evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15933390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather model loaded from file\n",
      "Scaler loaded from file\n",
      "Satellite model loaded from .keras file\n",
      "Real-time prediction system configured\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv('.env.local')\n",
    "\n",
    "class CyclonePredictionConfig:\n",
    "    def __init__(self):\n",
    "        self.OPENWEATHER_API_KEY = os.getenv('OPENWEATHER_API_KEY', 'your_api_key_here')\n",
    "        self.MAPBOX_ACCESS_TOKEN = os.getenv('MAPBOX_ACCESS_TOKEN', None)\n",
    "        self.GOOGLE_MAPS_API_KEY = os.getenv('GOOGLE_MAPS_API_KEY', None)\n",
    "        self.BING_MAPS_API_KEY = os.getenv('BING_MAPS_API_KEY', None)\n",
    "        self.LOG_DIRECTORY = \"logs\"\n",
    "        self.MODEL_DIRECTORY = \"models\"\n",
    "        self.IMG_HEIGHT = 150\n",
    "        self.IMG_WIDTH = 150\n",
    "        \n",
    "        os.makedirs(self.LOG_DIRECTORY, exist_ok=True)\n",
    "        os.makedirs(self.MODEL_DIRECTORY, exist_ok=True)\n",
    "    \n",
    "    def get_risk_level(self, probability):\n",
    "        if probability >= 0.8:\n",
    "            return \"EXTREME\"\n",
    "        elif probability >= 0.6:\n",
    "            return \"HIGH\"\n",
    "        elif probability >= 0.4:\n",
    "            return \"MODERATE\"\n",
    "        else:\n",
    "            return \"LOW\"\n",
    "\n",
    "config = CyclonePredictionConfig()\n",
    "\n",
    "def get_weather_data_for_prediction(city_name):\n",
    "    try:\n",
    "        base_url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "        params = {'q': city_name, 'appid': config.OPENWEATHER_API_KEY, 'units': 'metric'}\n",
    "        \n",
    "        response = requests.get(base_url, params=params, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            features = [\n",
    "                data['wind']['speed'],\n",
    "                data['main']['pressure'],\n",
    "                data['main']['temp']\n",
    "            ]\n",
    "            return np.array(features).reshape(1, -1), data\n",
    "        else:\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching weather data: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Load trained models\n",
    "def load_trained_models():\n",
    "    weather_model_loaded = None\n",
    "    scaler_loaded = None\n",
    "    satellite_model_loaded = None\n",
    "    \n",
    "    try:\n",
    "        with open('models/weather_model.pkl', 'rb') as f:\n",
    "            weather_model_loaded = pickle.load(f)\n",
    "        print(\"Weather model loaded from file\")\n",
    "    except:\n",
    "        weather_model_loaded = weather_model if 'weather_model' in globals() else None\n",
    "        if weather_model_loaded:\n",
    "            print(\"Weather model loaded from session\")\n",
    "    \n",
    "    try:\n",
    "        with open('models/scaler.pkl', 'rb') as f:\n",
    "            scaler_loaded = pickle.load(f)\n",
    "        print(\"Scaler loaded from file\")\n",
    "    except:\n",
    "        scaler_loaded = scaler if 'scaler' in globals() else None\n",
    "        if scaler_loaded:\n",
    "            print(\"Scaler loaded from session\")\n",
    "    \n",
    "    try:\n",
    "        # Try loading with new Keras format first\n",
    "        satellite_model_loaded = keras.models.load_model('models/my_model.keras')\n",
    "        print(\"Satellite model loaded from .keras file\")\n",
    "    except:\n",
    "        try:\n",
    "            # Fallback to older .h5 format\n",
    "            satellite_model_loaded = keras.models.load_model('models/satellite_model.h5')\n",
    "            print(\"Satellite model loaded from .h5 file\")\n",
    "        except:\n",
    "            satellite_model_loaded = satellite_model if 'satellite_model' in globals() else None\n",
    "            if satellite_model_loaded:\n",
    "                print(\"Satellite model loaded from session\")\n",
    "    \n",
    "    return weather_model_loaded, scaler_loaded, satellite_model_loaded\n",
    "\n",
    "weather_model_rt, scaler_rt, satellite_model_rt = load_trained_models()\n",
    "\n",
    "print(\"Real-time prediction system configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd08f963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather data for Visakhapatnam:\n",
      "  Location: Visakhapatnam, IN\n",
      "  Temperature: 31.72°C\n",
      "  Wind Speed: 5.73 m/s\n",
      "  Pressure: 999 hPa\n",
      "  Humidity: 58%\n",
      "  Coordinates: 17.6900, 83.2093\n",
      "Weather-based prediction:\n",
      "  Cyclone probability: 0.520\n",
      "  Risk level: MODERATE\n"
     ]
    }
   ],
   "source": [
    "target_city = \"Visakhapatnam\"\n",
    "weather_features, weather_raw = get_weather_data_for_prediction(target_city)\n",
    "\n",
    "if weather_features is not None and weather_raw is not None:\n",
    "    print(f\"Weather data for {target_city}:\")\n",
    "    print(f\"  Location: {weather_raw['name']}, {weather_raw['sys']['country']}\")\n",
    "    print(f\"  Temperature: {weather_raw['main']['temp']}°C\")\n",
    "    print(f\"  Wind Speed: {weather_raw['wind']['speed']} m/s\")\n",
    "    print(f\"  Pressure: {weather_raw['main']['pressure']} hPa\")\n",
    "    print(f\"  Humidity: {weather_raw['main']['humidity']}%\")\n",
    "    \n",
    "    latitude = weather_raw['coord']['lat']\n",
    "    longitude = weather_raw['coord']['lon']\n",
    "    print(f\"  Coordinates: {latitude:.4f}, {longitude:.4f}\")\n",
    "    \n",
    "    # Weather prediction\n",
    "    if weather_model_rt is not None and scaler_rt is not None:\n",
    "        weather_features_scaled = scaler_rt.transform(weather_features)\n",
    "        weather_prediction = weather_model_rt.predict_proba(weather_features_scaled)[0][1]\n",
    "        weather_risk_level = config.get_risk_level(weather_prediction)\n",
    "        \n",
    "        print(f\"Weather-based prediction:\")\n",
    "        print(f\"  Cyclone probability: {weather_prediction:.3f}\")\n",
    "        print(f\"  Risk level: {weather_risk_level}\")\n",
    "    else:\n",
    "        weather_prediction = None\n",
    "        weather_risk_level = \"UNKNOWN\"\n",
    "else:\n",
    "    print(f\"Failed to fetch weather data for {target_city}\")\n",
    "    weather_prediction = None\n",
    "    weather_risk_level = \"UNKNOWN\"\n",
    "    latitude = None\n",
    "    longitude = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e4f126f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching real satellite imagery for Visakhapatnam...\n",
      "No real satellite imagery available\n",
      "Check API keys in .env.local file\n"
     ]
    }
   ],
   "source": [
    "class SatelliteImageryService:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({'User-Agent': 'CyclonePrediction/1.0'})\n",
    "    \n",
    "    def fetch_openweather_satellite(self, lat, lon, layer='clouds_new'):\n",
    "        try:\n",
    "            zoom = 8\n",
    "            # Convert lat/lon to tile coordinates for better image quality\n",
    "            tile_x = int((lon + 180.0) / 360.0 * (1 << zoom))\n",
    "            tile_y = int((1.0 - np.log(np.tan(np.radians(lat)) + 1.0 / np.cos(np.radians(lat))) / np.pi) / 2.0 * (1 << zoom))\n",
    "            \n",
    "            url = f\"http://maps.openweathermap.org/maps/2.0/weather/{layer}/{zoom}/{tile_x}/{tile_y}.png\"\n",
    "            params = {'appid': self.config.OPENWEATHER_API_KEY}\n",
    "            \n",
    "            response = self.session.get(url, params=params, timeout=15)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "                filename = f\"{self.config.LOG_DIRECTORY}/satellite_{lat}_{lon}_{timestamp}.png\"\n",
    "                \n",
    "                with open(filename, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "                return filename\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"OpenWeather satellite fetch failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def fetch_mapbox_satellite(self, lat, lon):\n",
    "        \"\"\"Fetch real satellite imagery from Mapbox as backup\"\"\"\n",
    "        if not self.config.MAPBOX_ACCESS_TOKEN:\n",
    "            return None\n",
    "        try:\n",
    "            zoom = 12\n",
    "            width, height = 512, 512\n",
    "            url = f\"https://api.mapbox.com/styles/v1/mapbox/satellite-v9/static/{lon},{lat},{zoom}/{width}x{height}@2x\"\n",
    "            params = {'access_token': self.config.MAPBOX_ACCESS_TOKEN}\n",
    "            \n",
    "            response = self.session.get(url, params=params, timeout=15)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "                filename = f\"{self.config.LOG_DIRECTORY}/mapbox_satellite_{lat}_{lon}_{timestamp}.jpg\"\n",
    "                \n",
    "                with open(filename, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "                return filename\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Mapbox satellite fetch failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def load_and_preprocess_image(self, image_path):\n",
    "        \"\"\"Load and preprocess real satellite image for CNN analysis\"\"\"\n",
    "        try:\n",
    "            # Load image using PIL\n",
    "            img = Image.open(image_path)\n",
    "            \n",
    "            # Convert to RGB if necessary\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Resize to model input size\n",
    "            img_resized = img.resize((self.config.IMG_WIDTH, self.config.IMG_HEIGHT))\n",
    "            \n",
    "            # Convert to numpy array and normalize\n",
    "            img_array = np.array(img_resized) / 255.0\n",
    "            \n",
    "            # Add batch dimension\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            \n",
    "            return img_array\n",
    "        except Exception as e:\n",
    "            print(f\"Error preprocessing image: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def analyze_image_for_cyclone(self, image_path=None, image_array=None):\n",
    "        \"\"\"Analyze real satellite image for cyclone patterns\"\"\"\n",
    "        try:\n",
    "            if image_path:\n",
    "                # Load and preprocess real image file\n",
    "                processed_image = self.load_and_preprocess_image(image_path)\n",
    "            elif image_array is not None:\n",
    "                # Use provided image array\n",
    "                if len(image_array.shape) == 3:\n",
    "                    processed_image = np.expand_dims(image_array, axis=0)\n",
    "                else:\n",
    "                    processed_image = image_array\n",
    "            else:\n",
    "                return 0.5\n",
    "            \n",
    "            if satellite_model_rt is not None and processed_image is not None:\n",
    "                prediction = satellite_model_rt.predict(processed_image, verbose=0)\n",
    "                return float(prediction[0][0])\n",
    "            else:\n",
    "                # Fallback: basic image analysis\n",
    "                if image_path:\n",
    "                    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    if img is not None:\n",
    "                        # Simple pattern analysis\n",
    "                        cloud_density = np.mean(img) / 255.0\n",
    "                        contrast = np.std(img) / 255.0\n",
    "                        return min(0.9, cloud_density * 0.4 + contrast * 0.6)\n",
    "                return 0.5\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing image: {e}\")\n",
    "            return 0.5\n",
    "\n",
    "satellite_service = SatelliteImageryService(config)\n",
    "\n",
    "if latitude is not None and longitude is not None:\n",
    "    print(f\"Fetching real satellite imagery for {target_city}...\")\n",
    "    \n",
    "    # Try multiple sources for real satellite imagery\n",
    "    satellite_image_path = None\n",
    "    image_source = None\n",
    "    \n",
    "    # First try OpenWeatherMap satellite layer\n",
    "    satellite_image_path = satellite_service.fetch_openweather_satellite(latitude, longitude)\n",
    "    if satellite_image_path:\n",
    "        image_source = \"OpenWeatherMap\"\n",
    "        print(f\"OpenWeatherMap satellite image obtained\")\n",
    "    else:\n",
    "        # Try Mapbox satellite as backup\n",
    "        satellite_image_path = satellite_service.fetch_mapbox_satellite(latitude, longitude)\n",
    "        if satellite_image_path:\n",
    "            image_source = \"Mapbox\"\n",
    "            print(f\"Mapbox satellite image obtained\")\n",
    "    \n",
    "    if satellite_image_path and os.path.exists(satellite_image_path):\n",
    "        print(f\"Analyzing real satellite image from {image_source}...\")\n",
    "        \n",
    "        # Analyze the real satellite image\n",
    "        satellite_prediction = satellite_service.analyze_image_for_cyclone(image_path=satellite_image_path)\n",
    "        \n",
    "        # Display the satellite image with enhanced visualization\n",
    "        try:\n",
    "            img = Image.open(satellite_image_path)\n",
    "            \n",
    "            # Create enhanced visualization\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "            \n",
    "            # Original satellite image\n",
    "            ax1.imshow(img)\n",
    "            ax1.set_title(f'Real Satellite Image - {target_city}\\nSource: {image_source}\\nTimestamp: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "            ax1.axis('off')\n",
    "            \n",
    "            # Image analysis visualization\n",
    "            img_gray = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2GRAY)\n",
    "            ax2.imshow(img_gray, cmap='viridis')\n",
    "            ax2.set_title(f'Cloud Pattern Analysis\\nImage Size: {img.size}\\nFile: {os.path.basename(satellite_image_path)}')\n",
    "            ax2.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Display image properties\n",
    "            print(f\"Satellite Image Details:\")\n",
    "            print(f\"  Source: {image_source}\")\n",
    "            print(f\"  Size: {img.size[0]} x {img.size[1]} pixels\")\n",
    "            print(f\"  Mode: {img.mode}\")\n",
    "            print(f\"  File size: {os.path.getsize(satellite_image_path)} bytes\")\n",
    "            print(f\"  Saved as: {satellite_image_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Could not display image: {e}\")\n",
    "        \n",
    "        if satellite_prediction is not None:\n",
    "            satellite_risk_level = config.get_risk_level(satellite_prediction)\n",
    "            print(f\"Real satellite analysis results:\")\n",
    "            print(f\"  Image source: {image_source}\")\n",
    "            print(f\"  Cyclone probability: {satellite_prediction:.3f}\")\n",
    "            print(f\"  Risk level: {satellite_risk_level}\")\n",
    "        else:\n",
    "            satellite_risk_level = \"UNKNOWN\"\n",
    "            print(f\"Failed to analyze satellite image\")\n",
    "    else:\n",
    "        print(\"No real satellite imagery available\")\n",
    "        print(\"Check API keys in .env.local file\")\n",
    "        satellite_prediction = None\n",
    "        satellite_risk_level = \"UNKNOWN\"\n",
    "else:\n",
    "    print(\"No coordinates available for satellite analysis\")\n",
    "    satellite_prediction = None\n",
    "    satellite_risk_level = \"UNKNOWN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1717f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No satellite image available for detailed analysis\n",
      "Possible reasons:\n",
      "  - API key not configured in .env.local\n",
      "  - Network connectivity issues\n",
      "  - API service temporarily unavailable\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Satellite Image Visualization and Analysis\n",
    "if satellite_image_path and os.path.exists(satellite_image_path):\n",
    "    print(\"SATELLITE IMAGE ANALYSIS DETAILS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Load and analyze the satellite image\n",
    "    img = Image.open(satellite_image_path)\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    # Original satellite image (larger)\n",
    "    ax1 = plt.subplot(2, 3, (1, 2))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title(f'Real Satellite Image - {target_city}\\nSource: {image_source}\\nCoordinates: {latitude:.4f}, {longitude:.4f}', fontsize=12, weight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Grayscale version for cloud analysis\n",
    "    ax2 = plt.subplot(2, 3, 3)\n",
    "    img_gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "    ax2.imshow(img_gray, cmap='gray')\n",
    "    ax2.set_title('Grayscale Analysis')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # Cloud density visualization\n",
    "    ax3 = plt.subplot(2, 3, 4)\n",
    "    ax3.imshow(img_gray, cmap='Blues')\n",
    "    ax3.set_title('Cloud Density Map')\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    # Edge detection for pattern analysis\n",
    "    ax4 = plt.subplot(2, 3, 5)\n",
    "    edges = cv2.Canny(img_gray, 50, 150)\n",
    "    ax4.imshow(edges, cmap='Reds')\n",
    "    ax4.set_title('Pattern Detection')\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Histogram of pixel intensities\n",
    "    ax5 = plt.subplot(2, 3, 6)\n",
    "    ax5.hist(img_gray.flatten(), bins=50, alpha=0.7, color='skyblue')\n",
    "    ax5.set_title('Pixel Intensity Distribution')\n",
    "    ax5.set_xlabel('Intensity')\n",
    "    ax5.set_ylabel('Frequency')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Detailed image analysis\n",
    "    cloud_coverage = np.mean(img_gray) / 255.0\n",
    "    contrast = np.std(img_gray) / 255.0\n",
    "    brightness = np.mean(img_array)\n",
    "    \n",
    "    print(f\"IMAGE ANALYSIS METRICS:\")\n",
    "    print(f\"  Cloud Coverage: {cloud_coverage:.3f} (0=clear, 1=full clouds)\")\n",
    "    print(f\"  Contrast: {contrast:.3f} (higher = more varied patterns)\")\n",
    "    print(f\"  Average Brightness: {brightness:.1f}\")\n",
    "    print(f\"  Image Dimensions: {img.size[0]} x {img.size[1]} pixels\")\n",
    "    print(f\"  Color Mode: {img.mode}\")\n",
    "    print(f\"  File Path: {satellite_image_path}\")\n",
    "    \n",
    "    # Weather pattern interpretation\n",
    "    print(f\"\\nWEATHER PATTERN INTERPRETATION:\")\n",
    "    if cloud_coverage > 0.7:\n",
    "        print(\"  Heavy cloud cover detected - possible storm system\")\n",
    "    elif cloud_coverage > 0.4:\n",
    "        print(\"  Moderate cloud cover - scattered clouds\")\n",
    "    else:\n",
    "        print(\"  Light cloud cover - mostly clear skies\")\n",
    "    \n",
    "    if contrast > 0.3:\n",
    "        print(\"  High contrast patterns - possible organized weather system\")\n",
    "    else:\n",
    "        print(\"  Low contrast - uniform weather conditions\")\n",
    "\n",
    "else:\n",
    "    print(\"No satellite image available for detailed analysis\")\n",
    "    print(\"Possible reasons:\")\n",
    "    print(\"  - API key not configured in .env.local\")\n",
    "    print(\"  - Network connectivity issues\")\n",
    "    print(\"  - API service temporarily unavailable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac17f97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprehensive Cyclone Prediction for Visakhapatnam\n",
      "============================================================\n",
      "Analysis Time: 2025-07-06 17:35:53\n",
      "Location: Visakhapatnam\n",
      "Coordinates: 17.6900, 83.2093\n",
      "Individual Predictions:\n",
      "  Weather Model: 0.520 (MODERATE)\n",
      "Combined Assessment:\n",
      "  Risk Level: MODERATE\n",
      "  Probability: 0.520\n",
      "  Confidence: MEDIUM\n",
      "  Method: Weather Only\n",
      "Recommendations:\n",
      "  MODERATE RISK - Stay alert\n",
      "  - Monitor weather conditions regularly\n",
      "  - Have emergency plans ready\n",
      "  - Secure outdoor items\n",
      "Results saved to: logs/cyclone_prediction_20250706_173553.json\n",
      "Cyclone prediction analysis complete\n"
     ]
    }
   ],
   "source": [
    "print(f\"Comprehensive Cyclone Prediction for {target_city}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Combine predictions\n",
    "weather_available = weather_prediction is not None\n",
    "satellite_available = satellite_prediction is not None\n",
    "\n",
    "if weather_available and satellite_available:\n",
    "    combined_prediction = 0.6 * weather_prediction + 0.4 * satellite_prediction\n",
    "    confidence_level = \"HIGH\"\n",
    "    method = \"Weather + Satellite Combined\"\n",
    "elif weather_available:\n",
    "    combined_prediction = weather_prediction\n",
    "    confidence_level = \"MEDIUM\"\n",
    "    method = \"Weather Only\"\n",
    "elif satellite_available:\n",
    "    combined_prediction = satellite_prediction\n",
    "    confidence_level = \"MEDIUM\"\n",
    "    method = \"Satellite Only\"\n",
    "else:\n",
    "    combined_prediction = 0.5\n",
    "    confidence_level = \"LOW\"\n",
    "    method = \"No Model Available\"\n",
    "\n",
    "final_risk_level = config.get_risk_level(combined_prediction)\n",
    "\n",
    "print(f\"Analysis Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Location: {target_city}\")\n",
    "print(f\"Coordinates: {latitude:.4f}, {longitude:.4f}\" if latitude else \"N/A\")\n",
    "\n",
    "print(f\"Individual Predictions:\")\n",
    "if weather_available:\n",
    "    print(f\"  Weather Model: {weather_prediction:.3f} ({weather_risk_level})\")\n",
    "if satellite_available:\n",
    "    print(f\"  Satellite Model: {satellite_prediction:.3f} ({satellite_risk_level})\")\n",
    "\n",
    "print(f\"Combined Assessment:\")\n",
    "print(f\"  Risk Level: {final_risk_level}\")\n",
    "print(f\"  Probability: {combined_prediction:.3f}\")\n",
    "print(f\"  Confidence: {confidence_level}\")\n",
    "print(f\"  Method: {method}\")\n",
    "\n",
    "# Recommendations based on risk level\n",
    "print(f\"Recommendations:\")\n",
    "if combined_prediction >= 0.7:\n",
    "    print(\"  HIGH RISK - Take immediate precautions\")\n",
    "    print(\"  - Monitor weather updates continuously\")\n",
    "    print(\"  - Prepare emergency supplies\")\n",
    "    print(\"  - Consider evacuation if advised\")\n",
    "elif combined_prediction >= 0.5:\n",
    "    print(\"  MODERATE RISK - Stay alert\")\n",
    "    print(\"  - Monitor weather conditions regularly\")\n",
    "    print(\"  - Have emergency plans ready\")\n",
    "    print(\"  - Secure outdoor items\")\n",
    "else:\n",
    "    print(\"  LOW RISK - Normal conditions\")\n",
    "    print(\"  - Continue regular activities\")\n",
    "    print(\"  - Maintain weather awareness\")\n",
    "\n",
    "# Save results\n",
    "prediction_results = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'location': target_city,\n",
    "    'coordinates': {'lat': latitude, 'lon': longitude} if latitude else None,\n",
    "    'weather_prediction': weather_prediction,\n",
    "    'satellite_prediction': satellite_prediction,\n",
    "    'combined_prediction': combined_prediction,\n",
    "    'risk_level': final_risk_level,\n",
    "    'confidence': confidence_level,\n",
    "    'method': method\n",
    "}\n",
    "\n",
    "results_filename = f\"logs/cyclone_prediction_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(results_filename, 'w') as f:\n",
    "    json.dump(prediction_results, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to: {results_filename}\")\n",
    "print(\"Cyclone prediction analysis complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
